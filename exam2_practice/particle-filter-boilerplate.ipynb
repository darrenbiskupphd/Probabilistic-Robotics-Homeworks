{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6542d8",
   "metadata": {},
   "source": [
    "### Particle Filter Boilerplate Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ab858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "N = 1000             # Number of particles\n",
    "STATE_DIM = 3        # e.g., [x, y, theta]\n",
    "NOISE_COV = np.diag([0.1, 0.1, 0.05]) # The covariance matrix (R) for adding noise\n",
    "\n",
    "# 1. THE MOTION MODEL (Line 4)\n",
    "# Input: Current particle states (N x D), Control input u\n",
    "# Output: Predicted particle states (Deterministic)\n",
    "def motion_model(particles, u):\n",
    "    # TODO: Fill this in with your physics equations.\n",
    "    # Example (simple 2D movement):\n",
    "    # particles[:, 0] += u[0] # Move x\n",
    "    # particles[:, 1] += u[1] # Move y\n",
    "    return particles\n",
    "\n",
    "# 2. THE MEASUREMENT MODEL (Line 5)\n",
    "# Input: Particle states (N x D), Actual Sensor Reading z\n",
    "# Output: Unnormalized weights (N,) - Probability 0.0 to 1.0\n",
    "def measurement_model(particles, z):\n",
    "    # TODO: Fill this in with your sensor logic (Gaussian Likelihood).\n",
    "    # This function asks: \"How likely is observation 'z' if the robot is at 'particle'?\"\n",
    "    \n",
    "    # Example (Placeholder):\n",
    "    # dist = np.linalg.norm(particles[:, :2] - landmark, axis=1)\n",
    "    # weights = np.exp(-0.5 * (dist - z)**2 / sensor_noise)\n",
    "    \n",
    "    # For now, return uniform weights so code runs\n",
    "    return np.ones(len(particles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ac482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INITIALIZATION ---\n",
    "# Create the initial cloud (Line 2)\n",
    "# Initialize N particles randomly within some bounds\n",
    "particles = np.random.uniform(low=-10, high=10, size=(N, STATE_DIM))\n",
    "\n",
    "# Initialize weights uniformly (1/N)\n",
    "weights = np.ones(N) / N\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "# This simulates the loop \"for m = 1 to M\" over time steps\n",
    "for t in range(100):\n",
    "    \n",
    "    # 1. GET DATA (In a real scenario, this comes from the robot)\n",
    "    u_t = [1.0, 0.5]  # Control command\n",
    "    z_t = 5.2         # Sensor reading\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # STEP A: PREDICT / SAMPLING (Line 4)\n",
    "    # ------------------------------------------------------\n",
    "    \n",
    "    # A.1: Apply the Deterministic Motion Model (The \"x_bar\")\n",
    "    particles = motion_model(particles, u_t)\n",
    "    \n",
    "    # A.2: Add Random Noise (Sample from Covariance Matrix)\n",
    "    # This creates the distribution spread\n",
    "    noise = np.random.multivariate_normal(\n",
    "        mean=np.zeros(STATE_DIM), \n",
    "        cov=NOISE_COV, \n",
    "        size=N\n",
    "    )\n",
    "    particles += noise\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # STEP B: UPDATE / SCORING (Line 5)\n",
    "    # ------------------------------------------------------\n",
    "    \n",
    "    # Calculate how well each particle explains the sensor data\n",
    "    # \"weights\" here corresponds to w_t in the diagram\n",
    "    weights = measurement_model(particles, z_t)\n",
    "    \n",
    "    # Normalize weights so they sum to 1.0 (Crucial for probability)\n",
    "    weights += 1.e-300          # Avoid division by zero\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # STEP C: RESAMPLE (Lines 8-11)\n",
    "    # ------------------------------------------------------\n",
    "    \n",
    "    # 1. The Effective N check (Optional but recommended)\n",
    "    # If weights are very skewed, we resample. If distinct enough, we might skip.\n",
    "    # For this simple implementation, we resample every time.\n",
    "    \n",
    "    # 2. Draw indices based on weight probability\n",
    "    indices = np.random.choice(N, size=N, p=weights, replace=True)\n",
    "    \n",
    "    # 3. Create the new set (Line 10)\n",
    "    # This automatically \"clones\" good particles and \"kills\" bad ones\n",
    "    particles = particles[indices]\n",
    "    \n",
    "    # 4. Reset weights for the next round\n",
    "    weights = np.ones(N) / N\n",
    "\n",
    "    # --- ESTIMATION (Optional) ---\n",
    "    # Where do we think we are?\n",
    "    estimated_position = np.mean(particles, axis=0)\n",
    "    # print(f\"Step {t}: {estimated_position}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
